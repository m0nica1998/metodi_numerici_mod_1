{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a4584cc-3b64-47ed-be84-e232b76f0500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#CUMULANTE DI BINDER\n",
    "\n",
    "# I dati prodotti dal Metropolis sono correlati, quindi per calcolare l'errore statistico si usa\n",
    "# il metodo binned bootsrtap :\n",
    "# 1. Si divide il campione in N/k blocchi di dim k\n",
    "# 2. Si sceglie un nro random tra 1 e N/k e lo si mette nel nuovo campione. Si ripete finchè il nuovo campione ha dim N\n",
    "# 3. Si ripete la procedura fino a creare M nuovi campioni, poi si calcola B.C. per ogni campione. \n",
    "#    l'errore statistico è calcolato sull'array dei cumulanti \n",
    "# L'intera procedura si ripete incrementando k finchè l'errore non si stabilizza.\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def main():\n",
    "    with open(\"/Users/monicacesario/Desktop/modulo1/binder_045_200.dat\", \"r\") as f:\n",
    "        \n",
    "        xmagn = []\n",
    "        xene = []\n",
    "        nlatt = 200\n",
    "\n",
    "        #  for _ in range(1):\n",
    "        #     next(f) # Salta le prime tot righe\n",
    "        for line in f:\n",
    "            columns = line.split('\\t')\n",
    "            if len(columns) == 4:\n",
    "                \n",
    "                xmagn.append(abs(float(columns[2])))\n",
    "                xene.append(float(columns[3]))\n",
    "    \n",
    "    \"\"\"\n",
    "    with open(\"/Users/monicacesario/Desktop/Binder_vs_k.dat\", \"w\") as file1:\n",
    "        for k in range(1,2000):\n",
    "            y = bootstrap_error_binder(xmagn,k,200)\n",
    "            # Scrivo su un file i valori di Binder per poi fare analisi   (GRAFICO DI sigma C.B. IN FUNZIONE DI k)\n",
    "            file1.write(f\"{k}\\t{y}\\n\")  # scrive i valori delle colonne\n",
    "      \n",
    "    \"\"\"\n",
    "    with open(\"/Users/monicacesario/Desktop/Binder_045.dat\", \"a\") as file2:\n",
    "        x = binder_cumulant(xmagn)\n",
    "        y = bootstrap_error_binder(xmagn,2000,200)\n",
    "        file2.write(f\"{nlatt}\\t{x}\\t{y}\\n\")  # scrive i valori delle colonne\n",
    "        return 0  \n",
    "\n",
    "\n",
    "#costruisco nuovo campione dall'array originale di dati (k è la dimensione di ogni blocco)\n",
    "def get_blocks(sample,k):\n",
    "    #Converto in un array di np e ne prendo la lunghezza (se sample è già un array va bene lo stesso)\n",
    "    sample=np.asarray(sample)\n",
    "    N=len(sample)\n",
    "    print(N)\n",
    "    # Butto gli ultimi blocchi se k non divide N\n",
    "    if N%k!=0:\n",
    "        print(f\"Warning: {k} does not divide {N}. Throwing away last {N%k} elements.\")\n",
    "        sample=sample[0:N-N%k]\n",
    "        N=len(sample)\n",
    "\n",
    "    #Inizializzo i vettori dei blocchi\n",
    "    number_blocks=int(N/k)\n",
    "    blocks=[]\n",
    "\n",
    "    #Divido il campione in N/k blocchi\n",
    "    for j in range(number_blocks):\n",
    "        block=sample[j*k:(j+1)*k]\n",
    "        blocks.append(block)\n",
    "\n",
    "    return blocks\n",
    "\n",
    "#CREA CAMPIONI FAKE\n",
    "def new_sample(blocks):\n",
    "    #Prendo la lunghezza e inizializzo il nuovo array\n",
    "    number_blocks=len(blocks)\n",
    "    new_sample=[]\n",
    "\n",
    "    # Scelgo i blocchi a caso per costruire il nuovo campione\n",
    "    for j in range(number_blocks):\n",
    "        #Fix one block at random\n",
    "        u = random.randrange(number_blocks)\n",
    "        #Put it into new sample\n",
    "        new_sample.append(blocks[u])\n",
    "\n",
    "    #Turn list of arrays into one array\n",
    "    return np.concatenate(new_sample,axis=0)\n",
    "\n",
    "\n",
    "#BINDER CUMULANT\n",
    "def binder_cumulant(sample):\n",
    "    sample=np.asarray(sample)\n",
    "    sample4=sample**4\n",
    "    average_sample4=np.average(sample4)\n",
    "    sample2=sample**2\n",
    "    average_sample2=np.average(sample2)\n",
    "    return average_sample4/(average_sample2**2)\n",
    "\n",
    "\n",
    "#BOOTSTRAP ERROR ON BINDER CUMULANT\n",
    "def bootstrap_error_binder(sample,k,M):\n",
    "    #Convert into numpy array and get length\n",
    "    sample=np.asarray(sample)\n",
    "    N=len(sample)\n",
    "    #Divide sample into blocks\n",
    "    blocks=get_blocks(sample,k)\n",
    "    #Use blocks to build M new samples\n",
    "    new_samples=[]\n",
    "    for i in range(M):\n",
    "        new_samples.append(new_sample(blocks))\n",
    "    new_samples=np.asarray(new_samples)\n",
    "   \n",
    "    #Compute binder cumulant for each new sample\n",
    "    cumulant_array=np.zeros(M)\n",
    "    for j in range(M):\n",
    "        cumulant_array[j]=binder_cumulant(new_samples[j])\n",
    "    #Compute variance and statistical error from averages\n",
    "    bootstrap_variance=np.average(cumulant_array**2)-(np.average(cumulant_array)**2)\n",
    "    return np.sqrt(bootstrap_variance*M/(M-1))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcf67da-cedd-4fc0-82fe-2b8cc832b42e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099a7562-df78-45f8-a065-d02209289bac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
